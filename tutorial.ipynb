{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77d779e9-1812-4c32-adf5-019905a10ffb",
   "metadata": {},
   "source": [
    "# üöÄ Simulation-Based Inference Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bb2d29-e152-46dd-b7e1-049abd72f9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 1. Installation and Imports\n",
    "# Install necessary packages quietly\n",
    "!pip install sbi corner -q\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "from collections.abc import Callable\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sbi.inference import NPE, simulate_for_sbi\n",
    "from sbi.utils import BoxUniform\n",
    "from sbi.utils.user_input_checks import process_simulator\n",
    "from sbi.analysis import pairplot, conditional_pairplot\n",
    "from scipy import stats\n",
    "import warnings\n",
    "\n",
    "# Suppress minor warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "print(\"‚úÖ Libraries installed and imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0657f3ad-956c-4477-a44f-fac6bce3e2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use all available CPU cores for parallelization to speed up simulations\n",
    "num_workers = os.cpu_count()\n",
    "print(f\"‚öôÔ∏è Using {num_workers} available CPU cores for parallel processing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6408baa5-5226-40c9-9175-7c4fee7b5af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 2. Helper and Plotting Functions üõ†Ô∏è\n",
    "def analyze_posterior_statistics(\n",
    "        posterior_samples: torch.Tensor,\n",
    "        param_names: list[str],\n",
    "        true_params: torch.Tensor | list[float] | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Analyze and print posterior statistics, including correlations and comparison to true values.\n",
    "\n",
    "    Args:\n",
    "        posterior_samples: Samples from the posterior distribution, shape (n_samples, n_params).\n",
    "        param_names: A list of names for each parameter.\n",
    "        true_params: The true parameter values for comparison (optional).\n",
    "    Source:\n",
    "        https://github.com/janfb/euroscipy-2025-sbi-tutorial\n",
    "    \"\"\"\n",
    "    if isinstance(true_params, list):\n",
    "        true_params = torch.tensor(true_params)\n",
    "\n",
    "    # --- Calculate Statistics ---\n",
    "    posterior_mean = posterior_samples.mean(dim=0)\n",
    "    posterior_std = posterior_samples.std(dim=0)\n",
    "    posterior_median = posterior_samples.median(dim=0).values\n",
    "    lower_ci = torch.quantile(posterior_samples, 0.025, dim=0)\n",
    "    upper_ci = torch.quantile(posterior_samples, 0.975, dim=0)\n",
    "    posterior_corr = np.corrcoef(posterior_samples.T)\n",
    "\n",
    "    # --- Print Statistics Table ---\n",
    "    print(\"üìä Posterior Statistics\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"{'Parameter':<22} {'Mean ¬± Std':<20} {'Median':<15} {'95% Credible Interval':<20}\")\n",
    "    print(\"-\" * 70)\n",
    "    for i, name in enumerate(param_names):\n",
    "        mean_std_str = f\"{posterior_mean[i]:.3f} ¬± {posterior_std[i]:.3f}\"\n",
    "        median_str = f\"{posterior_median[i]:.3f}\"\n",
    "        ci_str = f\"[{lower_ci[i]:.3f}, {upper_ci[i]:.3f}]\"\n",
    "        print(f\"{name:<22} {mean_std_str:<20} {median_str:<15} {ci_str:<20}\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    # --- Print True Parameters Comparison (if provided) ---\n",
    "    if true_params is not None:\n",
    "        print(\"\\nüéØ Comparison with True Parameters:\")\n",
    "        for i, name in enumerate(param_names):\n",
    "            in_ci = bool(lower_ci[i] <= true_params[i] <= upper_ci[i])\n",
    "            symbol = \"‚úÖ\" if in_ci else \"‚ùå\"\n",
    "            print(f\"{symbol} {name:<22} True value: {true_params[i]:.3f} (In 95% CI: {in_ci})\")\n",
    "\n",
    "    # --- Print Correlations ---\n",
    "    print(\"\\nüîó Parameter Correlations:\")\n",
    "    n_params = posterior_samples.shape[1]\n",
    "    param_pairs = list(itertools.combinations(range(n_params), 2))\n",
    "    for i, j in param_pairs:\n",
    "        corr_value = posterior_corr[i, j]\n",
    "        name_i = param_names[i].split(\"(\")[0].strip()\n",
    "        name_j = param_names[j].split(\"(\")[0].strip()\n",
    "        print(f\"{name_i} / {name_j}: {corr_value:+.3f}\")\n",
    "\n",
    "\n",
    "def generate_posterior_predictive_simulations(\n",
    "        posterior,\n",
    "        observed_data: torch.Tensor,\n",
    "        simulate_func: Callable,\n",
    "        prior: torch.distributions.Distribution,\n",
    "        num_simulations: int = 1000,\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Generate posterior predictive simulations and the simulation for the MAP estimate.\n",
    "    Source:\n",
    "        https://github.com/janfb/euroscipy-2025-sbi-tutorial\n",
    "    \"\"\"\n",
    "    posterior.set_default_x(observed_data)\n",
    "    batch_simulator = process_simulator(simulate_func, prior, True)\n",
    "\n",
    "    # Generate simulations from posterior samples\n",
    "    _, predictive_simulations = simulate_for_sbi(\n",
    "        batch_simulator,\n",
    "        posterior,\n",
    "        num_simulations=num_simulations,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "\n",
    "    # Get the Maximum A Posteriori (MAP) estimate and simulate it\n",
    "    map_estimate = posterior.map()\n",
    "    map_simulation = simulate_func(map_estimate.squeeze())\n",
    "\n",
    "    return torch.from_numpy(map_simulation), predictive_simulations\n",
    "\n",
    "\n",
    "def plot_posterior_predictions(\n",
    "        predictions: torch.Tensor,\n",
    "        map_prediction: torch.Tensor,\n",
    "        time_span: float = 200.0,\n",
    "        dt: float = 0.1,\n",
    "        labels: list = [\"Prey\", \"Predator\"],\n",
    "        colors: list = [\"red\", \"blue\"],\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot posterior predictive time series with uncertainty bands.\n",
    "    Source:\n",
    "        https://github.com/janfb/euroscipy-2025-sbi-tutorial\n",
    "    \"\"\"\n",
    "    print(\"Plotting posterior predictive time series...\")\n",
    "    lower_bound = torch.quantile(predictions, 0.05, dim=0)\n",
    "    upper_bound = torch.quantile(predictions, 0.95, dim=0)\n",
    "    time_axis = np.arange(0, time_span, dt)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 7))\n",
    "    for i, (label, color) in enumerate(zip(labels, colors)):\n",
    "        # Plot MAP prediction\n",
    "        ax.plot(\n",
    "            time_axis,\n",
    "            map_prediction[:, i],\n",
    "            color=f\"dark{color}\",\n",
    "            linestyle=\"--\",\n",
    "            lw=2.5,\n",
    "            label=f\"MAP {label} Prediction\",\n",
    "        )\n",
    "        # Plot uncertainty bands (90% credible interval)\n",
    "        ax.fill_between(\n",
    "            time_axis,\n",
    "            lower_bound[:, i],\n",
    "            upper_bound[:, i],\n",
    "            color=color,\n",
    "            alpha=0.2,\n",
    "            label=f\"90% Credible Interval ({label})\",\n",
    "        )\n",
    "\n",
    "    ax.set_xlabel(\"Time\", fontsize=14)\n",
    "    ax.set_ylabel(\"Population\", fontsize=14)\n",
    "    ax.set_title(\"Predicted Future Population Dynamics\", fontsize=18)\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    ax.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"‚úÖ Utility functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4046725-d330-47c5-84f3-b52f99b2b028",
   "metadata": {},
   "source": [
    "## üéæ Part 1: The Ball Throw Physics Simulator\n",
    "\n",
    "Our first model is a simple physics simulation of a projectile with air resistance.\n",
    "\n",
    "**The Goal:** Imagine you are at a sports event. You can't see the athlete throw, but you can measure two things about the ball's flight:\n",
    "1.  **Landing Distance:** How far it traveled horizontally.\n",
    "2.  **Maximum Height:** The peak of its arc.\n",
    "\n",
    "Based *only* on these two observations, can we infer the **three hidden parameters** of the throw?\n",
    "-   `Initial Velocity` ($v_0$): How fast the ball was thrown.\n",
    "-   `Launch Angle` ($\\theta$): The angle of the throw.\n",
    "-   `Friction` ($\\mu$): A coefficient for air resistance.\n",
    "\n",
    "**The Physics:**\n",
    "Let's assume that the trajectory is governed by these differential equations:\n",
    "-   Horizontal motion: $\\frac{d^2x}{dt^2} = W - \\mu \\cdot \\frac{dx}{dt}$ (where $W$ is wind)\n",
    "-   Vertical motion: $\\frac{d^2y}{dt^2} = -g - \\mu \\cdot \\frac{dy}{dt}$ (where $g$ is gravity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e280722-a8aa-4b59-8123-ff77c952b232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Simulator and Prior Definition\n",
    "def ball_throw_simulator(\n",
    "        params: torch.Tensor | np.ndarray, return_trajectory: bool = False\n",
    ") -> torch.Tensor | tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Simulates a ball throw with air resistance and returns its summary statistics.\n",
    "\n",
    "    Args:\n",
    "        params: A tensor/array containing [initial_velocity, launch_angle, friction, wind?].\n",
    "        return_trajectory: If True, also returns the x and y coordinates of the flight path.\n",
    "\n",
    "    Returns:\n",
    "        A tensor with [landing_distance, max_height].\n",
    "    Source:\n",
    "        https://github.com/janfb/euroscipy-2025-sbi-tutorial\n",
    "    \"\"\"\n",
    "    if isinstance(params, torch.Tensor):\n",
    "        params = params.detach().cpu().numpy()\n",
    "\n",
    "    v0, angle, friction = params[0], params[1], params[2]\n",
    "    wind = params[3] if len(params) > 3 else 0.0\n",
    "    g, dt = 9.81, 0.01  # Gravity and time step\n",
    "\n",
    "    x, y = 0.0, 0.0\n",
    "    vx, vy = v0 * np.cos(angle), v0 * np.sin(angle)\n",
    "    x_traj, y_traj = ([x], [y])\n",
    "    max_height = 0.0\n",
    "\n",
    "    # Simulate up to 10,000 steps (100 seconds)\n",
    "    for _ in range(10_000):\n",
    "        # Update velocities with friction and gravity/wind\n",
    "        vx += (wind - friction * vx) * dt\n",
    "        vy += (-g - friction * vy) * dt\n",
    "        # Update position\n",
    "        x_new, y_new = x + vx * dt, y + vy * dt\n",
    "\n",
    "        # Stop if the ball hits the ground\n",
    "        if y_new < 0:\n",
    "            # Interpolate to find the exact landing spot\n",
    "            t_impact = -y / vy\n",
    "            landing_distance = x + vx * t_impact\n",
    "            break\n",
    "\n",
    "        x, y = x_new, y_new\n",
    "        max_height = max(max_height, y)\n",
    "        x_traj.append(x)\n",
    "        y_traj.append(y)\n",
    "    else: # Failsafe in case it never lands\n",
    "        landing_distance = x\n",
    "\n",
    "    # Add a small amount of observational noise to make it more realistic\n",
    "    noise_scale = 0.05\n",
    "    landing_distance *= (1 + np.random.randn() * noise_scale)\n",
    "    max_height *= (1 + np.random.randn() * noise_scale)\n",
    "\n",
    "    # Ensure observations are positive\n",
    "    observations = torch.tensor([max(0.1, landing_distance), max(0.1, max_height)], dtype=torch.float32)\n",
    "\n",
    "    if return_trajectory:\n",
    "        return observations, torch.tensor(x_traj), torch.tensor(y_traj)\n",
    "    return observations\n",
    "\n",
    "\n",
    "def create_ball_throw_prior(include_wind: bool = False):\n",
    "    \"\"\"Creates a uniform prior distribution for the ball throw parameters.\"\"\"\n",
    "    if include_wind:\n",
    "        # [v0, angle, friction, wind]\n",
    "        low = torch.tensor([5.0, 0.2, 0.0, -5.0])   # Wind can be headwind (-) or tailwind (+)\n",
    "        high = torch.tensor([30.0, 1.4, 0.5, 5.0])\n",
    "    else:\n",
    "        # [v0, angle, friction]\n",
    "        low = torch.tensor([5.0, 0.2, 0.0])\n",
    "        high = torch.tensor([30.0, 1.4, 0.5]) # Angle in radians (approx. 11¬∞ to 80¬∞)\n",
    "    return BoxUniform(low=low, high=high)\n",
    "\n",
    "\n",
    "def plot_trajectories(params_set, labels):\n",
    "    \"\"\"Helper function to plot multiple trajectories.\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for params, label in zip(params_set, labels):\n",
    "        _, x_traj, y_traj = ball_throw_simulator(params, return_trajectory=True)\n",
    "        plt.plot(x_traj, y_traj, label=label, lw=2.5)\n",
    "    plt.title(\"Sample Ball Throw Trajectories\", fontsize=16)\n",
    "    plt.xlabel(\"Distance (m)\")\n",
    "    plt.ylabel(\"Height (m)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.xlim(left=0)\n",
    "    plt.show()\n",
    "\n",
    "print(\"‚úÖ Ball throw simulator defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925c2eff-07de-4b88-b2ef-0a6cc23c0b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Interactive Trajectory Explorer\n",
    "# @markdown Drag the sliders to see how each parameter affects the ball's trajectory. This builds intuition for what our algorithm will learn.\n",
    "initial_velocity = 21  #@param {type:\"slider\", min:5.0, max:30.0, step:0.5}\n",
    "launch_angle_degrees = 27  #@param {type:\"slider\", min:10, max:80, step:1}\n",
    "friction_coefficient = 0.1 #@param {type:\"slider\", min:0.0, max:0.5, step:0.01}\n",
    "\n",
    "# Convert degrees to radians for the simulator\n",
    "launch_angle_radians = launch_angle_degrees * (np.pi / 180.0)\n",
    "interactive_params = torch.tensor([initial_velocity, launch_angle_radians, friction_coefficient])\n",
    "\n",
    "# Define some fixed throws for comparison\n",
    "strong_throw_params = torch.tensor([25.0, 0.7, 0.1])  # A powerful throw\n",
    "high_arc_params = torch.tensor([15.0, 1.2, 0.1])    # A high, looping throw\n",
    "\n",
    "plot_trajectories(\n",
    "    [strong_throw_params, high_arc_params, interactive_params],\n",
    "    [\"Strong Throw (25 m/s, 40¬∞)\", \"High-Arc Throw (15 m/s, 68¬∞)\", \"Your Custom Throw\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396cc58c-4776-406c-ac22-05f4027d7ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Perform Simulation-Based Inference\n",
    "# --- Step 1: Define the Prior ---\n",
    "prior = create_ball_throw_prior(include_wind=False)\n",
    "param_names_3d = [\"v‚ÇÄ (velocity)\", \"Œ∏ (angle)\", \"Œº (friction)\"]\n",
    "\n",
    "# --- Step 2: Set up the SBI pipeline ---\n",
    "# The `process_simulator` function wraps our Python simulator so `sbi` can use it.\n",
    "simulator = process_simulator(ball_throw_simulator, prior, False)\n",
    "# We use Neural Posterior Estimation (NPE) as our inference algorithm.\n",
    "npe = NPE(prior=prior)\n",
    "\n",
    "# --- Step 3: Generate Training Data ---\n",
    "# We run the simulator many times with parameters drawn from the prior.\n",
    "# This is the \"training set\" for our neural network.\n",
    "num_simulations = 2000  # Use 10,000+ for higher accuracy in a real project.\n",
    "print(f\"‚öôÔ∏è Generating {num_simulations} simulations... (This may take a moment)\")\n",
    "theta, x = simulate_for_sbi(\n",
    "    simulator,\n",
    "    prior,\n",
    "    num_simulations=num_simulations,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "print(f\"‚úÖ Generated {len(theta)} simulation-observation pairs.\")\n",
    "\n",
    "# --- Step 4: Train the Neural Network ---\n",
    "# The network learns the relationship between parameters (theta) and simulation outcomes (x).\n",
    "print(\"\\nüß† Training the neural posterior estimator...\")\n",
    "npe.append_simulations(theta, x).train()\n",
    "print(\"‚úÖ Training complete!\")\n",
    "\n",
    "# --- Step 5: Define the Observation and Build the Posterior ---\n",
    "# This is the data we actually observed. We'll use the \"Strong Throw\" as our target.\n",
    "observation_strong_throw = torch.tensor([50.5, 12.1])\n",
    "posterior = npe.build_posterior()\n",
    "print(f\"\\nüéØ Our observation: Distance={observation_strong_throw[0]}m, Height={observation_strong_throw[1]}m\")\n",
    "\n",
    "# --- Step 6: Sample from the Posterior ---\n",
    "# We draw samples from the learned posterior distribution, conditioned on our observation.\n",
    "print(\"üìà Sampling from the posterior distribution...\")\n",
    "posterior_samples = posterior.sample((10000,), x=observation_strong_throw)\n",
    "print(f\"‚úÖ Drew {len(posterior_samples)} posterior samples.\")\n",
    "print(\"\\nüéâ Inference complete! Let's analyze the results.\")\n",
    "\n",
    "# --- Step 7: Analyze and Visualize the Results ---\n",
    "# The pairplot shows the 1D and 2D marginals of the posterior.\n",
    "# The blue lines/dots mark the true parameters we're trying to recover.\n",
    "fig, axes = pairplot(\n",
    "    [posterior_samples],\n",
    "    points=strong_throw_params.unsqueeze(0),\n",
    "    labels=param_names_3d,\n",
    "    figsize=(8, 8),\n",
    ");\n",
    "plt.suptitle(\"Posterior Distribution for the Strong Throw\", fontsize=16, y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# Print detailed statistics\n",
    "_ = analyze_posterior_statistics(posterior_samples, param_names_3d, strong_throw_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2029990e-0bbf-4fc0-b9ae-fda708040ff0",
   "metadata": {},
   "source": [
    "### üí° Interpreting Posterior Correlations: The \"Wiggle Room\"\n",
    "\n",
    "You might notice in the pair plots that our results aren't single, sharp points but are often elongated or slanted \"blobs.\" This is a key insight, *not* a flaw! It shows that the data can be explained by a range of different parameter combinations. This \"wiggle room\" happens for a few important reasons:\n",
    "\n",
    "1.  **Parameter Trade-Offs:** Often, a change in one parameter can be compensated for by a change in another. The posterior plot reveals the exact nature of this trade-off.\n",
    "\n",
    "2.  **Identifiability Limits:** The summary statistics we use (distance and height) might not be perfect. Multiple different parameter sets could produce summary statistics that are very similar, making it hard for the model to distinguish between them. The posterior honestly reflects this ambiguity.\n",
    "\n",
    "\n",
    "#### Why This is So Useful\n",
    "\n",
    "Understanding these correlations is a core benefit of using SBI over simple optimization. Instead of just one \"best\" answer, we get a complete map of all plausible solutions. This helps us:\n",
    "\n",
    "* **Pinpoint what the data tells us:** A narrow posterior for a parameter means the data has strongly constrained it. A broad, correlated posterior tells us the data can only constrain a specific *combination* of parameters.\n",
    "\n",
    "* **Know when we need more data:** If key parameters remain too uncertain or correlated, the plot is telling us that we might need more informative summary statistics or different kinds of data to break the trade-offs.\n",
    "\n",
    "* **Uncover scientific insights:** These statistical correlations often reflect real-world phenomena. For this model, it reveals the physical relationship between velocity, angle, friction, and wind (next section), providing a complete picture of the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52ed009-e39e-4016-ac83-2dbb5de882c9",
   "metadata": {},
   "source": [
    "### üìà Conditional Posterior Distibution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c12d1f-20a8-4788-a872-1c30942191ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi.analysis import conditional_pairplot\n",
    "\n",
    "# The posterior must have a `default_x`.\n",
    "posterior = npe.build_posterior().set_default_x(observation_strong_throw)\n",
    "\n",
    "\n",
    "_ = conditional_pairplot(\n",
    "    density=posterior,\n",
    "    points=[strong_throw_params.unsqueeze(0)],\n",
    "    condition=strong_throw_params,\n",
    "    limits=torch.tensor([[5.0, 30.0], [0.2, 1.4], [0.0, 0.5]]),\n",
    "    labels=param_names_3d,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3361d8-2c03-4aa1-b5f8-a2c350f24b1d",
   "metadata": {},
   "source": [
    "### ü§∏ Exercise 1: Two Different Athletes\n",
    "\n",
    "**Scenario:** We have data from two athletes, but we only see the final result of their throws.\n",
    "\n",
    "* **Athlete A** is a \"power thrower\": **50.3m** distance, **12.1m** max height.\n",
    "* **Athlete B** is a \"high-arc specialist\": **12.1m** distance, **9.5m** max height.\n",
    "\n",
    "**Question:** Based *only* on these two outcomes, what can we infer about their throwing styles (velocity, angle, friction)?\n",
    "\n",
    "**Implementation:** We can reuse our already-trained `posterior` object. We just need to condition it on the new observations for each athlete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b435886-f32d-490d-b283-336884d0d865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "455867b1-b544-4146-9f44-167de27f924d",
   "metadata": {},
   "source": [
    "### üí® Exercise 2: Inferring an Unknown Wind\n",
    "\n",
    "**Scenario:** A throw is made under unknown weather conditions. The ball travels an unusually long distance for its apparent arc. We suspect there was a tailwind helping it along.\n",
    "\n",
    "**Task:** Add **wind strength** as a fourth parameter to our model and infer it from a new observation.\n",
    "\n",
    "* **New Parameter:** `wind` (m/s), can be negative (headwind) or positive (tailwind).\n",
    "* **New Prior:** A 4D uniform distribution including wind from -5.0 to 5.0 m/s.\n",
    "* **Observation:** A throw lands at **65.0 meters** and reached a max height of **11.0 meters**.\n",
    "\n",
    "**Implementation:** Since we've added a new parameter, our previous neural network is no longer valid. We must retrain from scratch with a new 4D prior and new simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e57c31-8a64-44fb-abaf-2fcbc9936e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5128ee9f-3a54-4b38-bed9-fe65afc15807",
   "metadata": {},
   "source": [
    "## ü¶ä Part 2: Lotka-Volterra Predator-Prey Model\n",
    "\n",
    "Next, we'll tackle a classic model in theoretical ecology: the Lotka-Volterra equations, which describe the population dynamics of a predator and its prey.\n",
    "\n",
    "**The Goal:** Given a time-series of prey and predator populations, can we infer the four fundamental parameters that govern their interaction?\n",
    "\n",
    "**The Equations:**\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{d\\text{Prey}}{dt} &= \\alpha \\cdot \\text{Prey} - \\beta \\cdot \\text{Prey} \\cdot \\text{Predator} \\\\\n",
    "\\frac{d\\text{Predator}}{dt} &= \\delta \\cdot \\text{Prey} \\cdot \\text{Predator} - \\gamma \\cdot \\text{Predator}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "**The Parameters:**\n",
    "-   `Œ± (alpha)`: **Prey birth rate**.\n",
    "-   `Œ≤ (beta)`: **Predation rate** (how effectively predators hunt prey).\n",
    "-   `Œ¥ (delta)`: **Predator reproduction rate** (how efficiently predators turn food into offspring).\n",
    "-   `Œ≥ (gamma)`: **Predator death rate**.\n",
    "\n",
    "**The Challenge:** Unlike the ball throw, the output of this simulator is not just two numbers, but a long time series. We need to compress this data into a set of **summary statistics** that capture its essential features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84de7910-449a-4855-a931-a85537511203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Simulator and Summary Statistics\n",
    "def lotka_volterra_simulation(\n",
    "        parameters: np.ndarray,\n",
    "        t_span: float = 200.0,\n",
    "        dt: float = 0.1,\n",
    "        y0: np.ndarray = np.asarray([40.0, 9.0])\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Simulates the Lotka-Volterra model using a simple Euler method.\n",
    "\n",
    "    Args:\n",
    "        parameters: A numpy array [alpha, beta, delta, gamma].\n",
    "        t_span: Total simulation time.\n",
    "        dt: Time step for the simulation.\n",
    "        y0: Initial populations [prey, predator].\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (timesteps, 2) with the population dynamics.\n",
    "    Source:\n",
    "        https://github.com/janfb/euroscipy-2025-sbi-tutorial\n",
    "    \"\"\"\n",
    "    alpha, beta, delta, gamma = parameters\n",
    "    timesteps = int(t_span / dt)\n",
    "    y = np.zeros((timesteps, 2))\n",
    "    y[0] = y0\n",
    "\n",
    "    for i in range(1, timesteps):\n",
    "        prey, predator = y[i-1]\n",
    "        dprey_dt = alpha * prey - beta * prey * predator\n",
    "        dpredator_dt = delta * prey * predator - gamma * predator\n",
    "        y[i] = y[i-1] + np.asarray([dprey_dt, dpredator_dt]) * dt\n",
    "        # Ensure populations don't go below zero\n",
    "        y[i][y[i] < 0] = 0\n",
    "    return y\n",
    "\n",
    "\n",
    "def _get_stats(population: np.ndarray, use_autocorrelation: bool) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Helper to calculate summary stats for a single population time series.\n",
    "    Source:\n",
    "        https://github.com/janfb/euroscipy-2025-sbi-tutorial\n",
    "    \"\"\"\n",
    "    # Moments: mean, std, max, skewness, kurtosis\n",
    "    moments = np.array([\n",
    "        np.mean(population), np.std(population), np.max(population),\n",
    "        stats.skew(population), stats.kurtosis(population)\n",
    "    ])\n",
    "    if not use_autocorrelation:\n",
    "        return moments\n",
    "\n",
    "    # Autocorrelation at specific time lags\n",
    "    mean_centered_pop = population - np.mean(population)\n",
    "    autocorr_full = np.correlate(mean_centered_pop, mean_centered_pop, mode=\"full\")\n",
    "    lag_0_corr = autocorr_full[autocorr_full.size // 2]\n",
    "\n",
    "    if lag_0_corr > 1e-6:\n",
    "        normalized_autocorr = (autocorr_full / lag_0_corr)[autocorr_full.size // 2 :]\n",
    "        # Lags correspond to time delays of 1, 5, 10, 20, and 40 units of time\n",
    "        lags_to_take = [10, 50, 100, 200, 400]\n",
    "        autocorr = normalized_autocorr[lags_to_take]\n",
    "    else: # If variance is zero, autocorrelation is undefined\n",
    "        autocorr = np.zeros(5)\n",
    "\n",
    "    return np.concatenate([moments, autocorr])\n",
    "\n",
    "\n",
    "def summarize_simulation(\n",
    "        simulation_result: np.ndarray, use_autocorrelation: bool = False\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts a simulation time series into summary statistics.\n",
    "    Adds a bit of noise to simulate real-world measurement error.\n",
    "    Source:\n",
    "        https://github.com/janfb/euroscipy-2025-sbi-tutorial\n",
    "    \"\"\"\n",
    "    noise = np.random.randn(*simulation_result.shape)\n",
    "    noisy_populations = simulation_result + noise\n",
    "    prey_stats = _get_stats(noisy_populations[:, 0], use_autocorrelation)\n",
    "    predator_stats = _get_stats(noisy_populations[:, 1], use_autocorrelation)\n",
    "    return np.concatenate([prey_stats, predator_stats])\n",
    "\n",
    "def get_summary_labels(use_autocorrelation: bool = False) -> list:\n",
    "    \"\"\"\n",
    "    Returns a list of names for the summary statistics.\n",
    "    Source:\n",
    "        https://github.com/janfb/euroscipy-2025-sbi-tutorial\n",
    "    \"\"\"\n",
    "    moment_labels = [\"Mean\", \"Std\", \"Max\", \"Skew\", \"Kurtosis\"]\n",
    "    if use_autocorrelation:\n",
    "        acf_labels = [\"ACF Lag 10\", \"ACF Lag 50\", \"ACF Lag 100\", \"ACF Lag 200\", \"ACF Lag 400\"]\n",
    "        stat_labels = moment_labels + acf_labels\n",
    "    else:\n",
    "        stat_labels = moment_labels\n",
    "    return [f\"Prey {lbl}\" for lbl in stat_labels] + [f\"Predator {lbl}\" for lbl in stat_labels]\n",
    "\n",
    "\n",
    "# This is our master simulator function for SBI. It runs the simulation AND summarizes it.\n",
    "def lotka_volterra_sbi_simulator(parameters, use_autocorrelation=False):\n",
    "    populations = lotka_volterra_simulation(parameters)\n",
    "    return summarize_simulation(populations, use_autocorrelation)\n",
    "\n",
    "print(\"‚úÖ Lotka-Volterra simulator and summarizer defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9622c9a-80cc-4222-8372-319664ef887c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Interactive LV Explorer & Summary Statistics\n",
    "# @markdown Drag the sliders to see how the parameters change the population cycles.\n",
    "Œ± = 0.12  #@param {type:\"slider\", min:0.05, max:0.15, step:0.01}\n",
    "Œ≤ = 0.015  #@param {type:\"slider\", min:0.01, max:0.03, step:0.005}\n",
    "Œ¥ = 0.01  #@param {type:\"slider\", min:0.005, max:0.03, step:0.005}\n",
    "Œ≥ = 0.085  #@param {type:\"slider\", min:0.005, max:0.15, step:0.01}\n",
    "\n",
    "# --- Generate a ground-truth simulation ---\n",
    "true_params_lv = np.asarray([Œ±, Œ≤, Œ¥, Œ≥])\n",
    "observed_time_series = lotka_volterra_simulation(true_params_lv)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 4))\n",
    "ax.plot(np.arange(0, 200, 0.1), observed_time_series)\n",
    "ax.legend([\"Prey\", \"Predator\"])\n",
    "ax.set_xlabel(\"Time\")\n",
    "ax.set_ylabel(\"Population\")\n",
    "ax.set_title(\"Lotka-Volterra Population Dynamics\")\n",
    "plt.show()\n",
    "\n",
    "# --- Calculate summary statistics for this \"observed\" data ---\n",
    "# We will start by using only the basic moment-based statistics.\n",
    "USE_AUTOCORRELATION = False # This is the key setting for Exercise 3\n",
    "observed_summary = summarize_simulation(observed_time_series, use_autocorrelation=USE_AUTOCORRELATION)\n",
    "data_labels = get_summary_labels(use_autocorrelation=USE_AUTOCORRELATION)\n",
    "\n",
    "print(\"üìã Observed Summary Statistics (using moments only):\")\n",
    "for label, value in zip(data_labels, observed_summary):\n",
    "    print(f\"{label:20s}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da595cb-7122-45b4-b81a-ee0ac0dc8c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Perform SBI on the Lotka-Volterra Model\n",
    "# --- Step 1: Define Prior ---\n",
    "lv_param_names = [\"Œ± (prey birth)\", \"Œ≤ (predation)\", \"Œ¥ (predator effic.)\", \"Œ≥ (predator death)\"]\n",
    "lower_bound = torch.tensor([0.05, 0.01, 0.005, 0.005])\n",
    "upper_bound = torch.tensor([0.15, 0.03, 0.03, 0.15])\n",
    "prior_lv = BoxUniform(low=lower_bound, high=upper_bound)\n",
    "\n",
    "# --- Step 2: Set up SBI Pipeline ---\n",
    "# Note: we pass the `use_autocorrelation` flag to our simulator wrapper\n",
    "simulator_lv = lambda params: lotka_volterra_sbi_simulator(params, use_autocorrelation=USE_AUTOCORRELATION)\n",
    "simulator_lv = process_simulator(simulator_lv, prior_lv, False)\n",
    "npe_lv = NPE(prior=prior_lv)\n",
    "\n",
    "# --- Step 3: Generate Data & Train ---\n",
    "num_simulations_lv = 2000\n",
    "print(f\"‚öôÔ∏è Generating {num_simulations_lv} simulations...\")\n",
    "theta_lv, x_lv = simulate_for_sbi(simulator_lv, prior_lv, num_simulations=num_simulations_lv, num_workers=num_workers)\n",
    "print(\"üß† Training neural posterior estimator...\")\n",
    "npe_lv.append_simulations(theta_lv, x_lv).train()\n",
    "posterior_lv = npe_lv.build_posterior()\n",
    "print(\"‚úÖ Training Complete!\")\n",
    "\n",
    "# --- Step 4: Sample from Posterior ---\n",
    "print(\"\\nüìà Sampling from posterior...\")\n",
    "observed_data_lv = torch.tensor(observed_summary, dtype=torch.float32)\n",
    "posterior_samples_lv = posterior_lv.sample((10000,), x=observed_data_lv)\n",
    "print(f\"‚úÖ Drew {len(posterior_samples_lv)} posterior samples.\")\n",
    "\n",
    "# --- Step 5: Analyze and Visualize ---\n",
    "fig = pairplot(\n",
    "    posterior_samples_lv,\n",
    "    points=true_params_lv,\n",
    "    labels=[r\"$\\alpha$\", r\"$\\beta$\", r\"$\\delta$\", r\"$\\gamma$\"],\n",
    "    figsize=(9, 9),\n",
    "    limits=[(low, high) for low, high in zip(lower_bound, upper_bound)],\n",
    ")\n",
    "plt.suptitle(\"Posterior Distribution of Lotka-Volterra Parameters\", fontsize=20, y=1.02)\n",
    "plt.show()\n",
    "\n",
    "_ = analyze_posterior_statistics(\n",
    "    posterior_samples=posterior_samples_lv,\n",
    "    param_names=lv_param_names,\n",
    "    true_params=torch.from_numpy(true_params_lv),\n",
    ")\n",
    "# @title Posterior Predictive Check\n",
    "# --- Step 6: Posterior Predictive Check ---\n",
    "# This is a crucial step: can our inferred parameters generate simulations that look like the original data?\n",
    "map_sim, pred_sims = generate_posterior_predictive_simulations(\n",
    "    posterior=posterior_lv,\n",
    "    observed_data=observed_data_lv,\n",
    "    simulate_func=lotka_volterra_simulation, # Use the raw simulator here\n",
    "    prior=prior_lv,\n",
    "    num_simulations=1000,\n",
    ")\n",
    "\n",
    "plot_posterior_predictions(predictions=pred_sims, map_prediction=map_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564cfa0b-8d69-4b2d-8c39-1381a027b662",
   "metadata": {},
   "source": [
    "### üî¨ Exercise 3: The Value of Better Statistics\n",
    "\n",
    "**Scenario:** Our first analysis (using only moments) worked, but the posterior predictive plot shows that the uncertainty in our forecast grows very quickly. Can we do better?\n",
    "\n",
    "**Hypothesis:** The moments (mean, std, etc.) don't capture the *temporal structure* of the time series (e.g., the speed of the oscillations). Autocorrelation, which measures how a signal correlates with a delayed copy of itself, should provide this missing information.\n",
    "\n",
    "**Your Task:**\n",
    "1.  Go back to the **\"Interactive LV Explorer & Summary Statistics\"** cell.\n",
    "2.  Set the variable `USE_AUTOCORRELATION = True`.\n",
    "3.  Re-run that cell and all the subsequent cells for the Lotka-Volterra model.\n",
    "4.  Compare the new results (posterior distributions and predictive plots) with the old ones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86353cc9-fa00-4cb7-9014-6c549a95a831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "359fd21d-a6c3-4ecf-9d25-999671236eac",
   "metadata": {},
   "source": [
    "## üåé Exercise 4: Real-World Fox and Rabbit Data\n",
    "\n",
    "**Scenario:** We have obtained real-world data on the number of hunted **foxes (predator)** and **wild rabbits (prey)** in Saxony, Germany, from 1991 to 2023. Can we use our Lotka-Volterra model and SBI to find parameters that describe this real ecological system and predict its future?\n",
    "\n",
    "**The Data:**\n",
    "-   Source: Saxony State Ministry for the Environment and Agriculture([Excel file in the PDF document](https://www.medienservice.sachsen.de/medien/medienobjekte/117580)).\n",
    "\n",
    "**Your Task:**\n",
    "1.  **Preprocess the Data:** Calculate summary statistics from the real time-series data. This will be our `observation`.\n",
    "2.  **Define a Prior:** Choose a reasonable prior range for the LV parameters. We may need a wider prior than before, as real-world dynamics can be different.\n",
    "3.  **Run the Inference:** Execute the full SBI pipeline using the real data as the target observation.\n",
    "4.  **Analyze and Predict:** Analyze the inferred posterior and generate posterior predictive simulations to forecast the populations into the future.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc9f816-8b05-40ca-8480-f5317466b29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Data Preparation\n",
    "# Data source: https://www.medienservice.sachsen.de/medien/medienobjekte/117580\n",
    "\n",
    "times = np.arange(1991, 1991 + 33)\n",
    "foxes_raw = np.array([8100.0, 16446.0, 22152.0, 24413.0, 30010.0, 23240.0, 28922.0,\n",
    "                      30949.0, 32598.0, 26475.0, 29037.0, 28537.0, 23503.0, 24619.0,\n",
    "                      26604.0, 21376.0, 28169.0, 27091.0, 24705.0, 24592.0, 22235.0,\n",
    "                      18618.0, 13496.0, 14365.0, 16479.0, 14752.0, 13332.0, 14893.0,\n",
    "                      16303.0, 17797.0, 13869.0, 14000.0, 16262.0])\n",
    "rabbits_raw = np.array([274.0, 355.0, 293.0, 271.0, 174.0, 73.0, 100.0, 91.0, 69.0,\n",
    "                        73.0, 45.0, 37.0, 63.0, 47.0, 91.0, 25.0, 36.0, 55.0, 32.0,\n",
    "                        37.0, 38.0, 21.0, 71.0, 44.0, 46.0, 18.0, 10.0, 0.0, 21.0,\n",
    "                        0.0, 1.0, 8.0, 1.0])\n",
    "\n",
    "# We scale the data to be in a similar numerical range as our simulator (e.g., by thousands)\n",
    "# This helps with numerical stability.\n",
    "foxes = foxes_raw / 1000\n",
    "rabbits = rabbits_raw / 1000\n",
    "real_data_timeseries = np.stack([rabbits, foxes], axis=1) # Note: Prey first, then Predator\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(15, 7))\n",
    "color_fox = 'tab:blue'\n",
    "ax1.set_xlabel('Year', fontsize=12)\n",
    "ax1.set_ylabel('Foxes (in thousands)', color=color_fox, fontsize=12)\n",
    "ax1.plot(times, foxes, color=color_fox, marker='o', label='F√ºchse (Foxes)')\n",
    "ax1.tick_params(axis='y', labelcolor=color_fox)\n",
    "ax2 = ax1.twinx()\n",
    "color_rabbit = 'tab:red'\n",
    "ax2.set_ylabel('Rabbits (in thousands)', color=color_rabbit, fontsize=12)\n",
    "ax2.plot(times, rabbits, color=color_rabbit, marker='x', linestyle='--', label='Wildkaninchen (Rabbits)')\n",
    "ax2.tick_params(axis='y', labelcolor=color_rabbit)\n",
    "plt.title('Foxes and Rabbits in Saxony (1991-2023)', fontsize=16, pad=20)\n",
    "ax1.legend(loc='upper left'); ax2.legend(loc='upper right')\n",
    "fig.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c882c5-bd1c-4a43-bb3a-024089cf9dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10a8f76f-be65-4079-a282-80c1b04e4317",
   "metadata": {},
   "source": [
    "## üìö References and Credits\n",
    "\n",
    "* **sbi Package Documentation:** [sbi.readthedocs.io](https://sbi.readthedocs.io/)\n",
    "* This tutorial was inspired by and adapts materials from:\n",
    "    * Boelts, J. (2025). EuroSciPy 2025: Simulation-Based Inference Tutorial. [github.com/janfb/euroscipy-2025-sbi-tutorial](https://github.com/janfb/euroscipy-2025-sbi-tutorial)\n",
    "    * Deistler, M., et al. (2025). Simulation-Based Inference: A Practical Guide.\n",
    "    * Cranmer, K., Brehmer, J., & Louppe, G. (2020). The frontier of simulation-based inference. *PNAS*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92b7247-d553-48d2-9b6c-82e8fe128d37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
